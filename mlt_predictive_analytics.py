# -*- coding: utf-8 -*-
"""MLT Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rD6Nr5KKmwrZv24kMGDMXOz6efCE8QD1

# **Proyek Machine Learning Terapan**

*   Nama        : Muhammad Khalish
*   E-mail      : khalish.21muhammad07@gmail.com
*   Dicoding ID : https://www.dicoding.com/users/mkhlst/
*   Topic       : Agriculture

# **Deskripsi proyek**

Saat ini, proses penanaman benih pada lahan yang dilakukan di Indonesia berdasarkan komoditas unggulan di daerah masing-masing. Namun, ada beberapa hal yang perlu diperhatikan dalam memilih jenis komoditas yang ingin dibudidayakan. hal ini dikarenakan lahan pada masing-masing daerah memiliki kandungan hara yang berbeda. Hal ini juga yang menyebabkan produktivitas pertanian tidak maksimal. oleh karena itu, proyek ini bertujuan untuk mengembangkan model machine learning yang dapat memprediksi kecocokan tanah dengan komoditas tanaman.

# **Import library yang dibutuhkan**
"""

!pip install -q kaggle

# Commented out IPython magic to ensure Python compatibility.
# Import load data library
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
# Import preprocessing library
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
# Import train test split
from sklearn.model_selection import train_test_split
# Import Model
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score

"""# **Data Understanding**

Merupakan proses untuk memahami informasi dalam data dan menentukan kualitas data

## **Data Loading**

Merupakan proses untuk memuat dataset agar dapat digunakan. Dataset berikut sudah dibersihkan terlebih dahulu uleh pembuat, sehingga mudah dan ramah digunakan.

**Informasi Dataset**

| Jenis | Keterangan |
| ------ | ------ |
| Title | Crop Recommendation |
| Source | [Kaggle](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset) |
| Maintainer | [Atharva Ingle âš¡](https://www.kaggle.com/atharvaingle) |
| License | Apache 2.0 |
| Visibility | Publik |
| Tags | Tabular, Agriculture, Recommender Systems |
| Usability | 7.06 |
"""

# Membuat direktori baru bernama kaggle
!rm -rf ~/.kaggle && mkdir ~/.kaggle/

# Menyalin berkas kaggle.json pada direktori aktif saat ini ke direktori kaggle
!mv kaggle.json ~/.kaggle/kaggle.json

# Mengubah permission berkas
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d atharvaingle/crop-recommendation-dataset

# Ekstrak berkas zip
!unzip /content/crop-recommendation-dataset.zip

df = pd.read_csv('/content/Crop_recommendation.csv')
df.head()

"""Berdasarkan informasi diatas, diketahui bahwa terdapat 8 kolom, yakni

* N --> perbandingan kandungan nitrogen pada tanah
* P --> perbandingan kandungan fosfor pada tanah
* K --> perbandingan kandungan potasium pada tanah
* temperature --> temperatur pada satuan celsius
* humidity --> persentase kelembaban tanah
* ph --> nilai pH tanah
* rainfall --> intensitas hujan dalam mm
* label --> jenis tanaman yang cocok

## **Exploratory Data Analysis (EDA)**

Exploratory data analysis atau sering disingkat EDA merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data

### **Deskripsi Variabel**
"""

df.info()

"""Berdasarkan informasi diatas, terdapat total `2200 baris` dan `8 kolom` yang terdiri dari

* 7 kolom numerik, dimana 3 kolom dengan tipe data integer (N, P, dan K) dan 4 kolom dengan tipe data float (temperature, humidity, ph, dan rainfall)
* 1 kolom kategori dengan tipe data object yaitu label yang merupakan data jenis tanaman

### **Menangani Missing Value dan Outlier**
"""

df.isna().sum()

print('Jumlah duplikat:', df.duplicated().sum())
print(df.shape)
df.describe()

sns.boxplot(x = df['N'])

sns.boxplot(x = df['P'])

sns.boxplot(x = df['K'])

sns.boxplot(x = df['temperature'])

sns.boxplot(x = df['humidity'])

sns.boxplot(x = df['ph'])

sns.boxplot(x = df['rainfall'])

"""Setelah dilakukan pengecekan menggunakan fungsi `isna.sum()` dan `duplicated.sum()`, tidak terdapat informasi data yang hilang dan terduplikasi. Namun, terdapat outlier pada fitur-fitur seperti P, K, temperature, humidity, pH, dan rainfall dengan menggunakan teknik visualisasi data boxplot."""

# Memilih kolom yang berisi tipe data numerik
numeric_col = df.select_dtypes(include=np.number).columns
numeric_col = [col for col in numeric_col if col != 'label']

# Menangani outlier menggunakan IQR Method
Q1 = df[numeric_col].quantile(0.25)
Q3 = df[numeric_col].quantile(0.75)
IQR = Q3 - Q1

filtered_df = df[~((df[numeric_col] < (Q1 - 1.5 * IQR)) |(df[numeric_col] > (Q3 + 1.5 * IQR))).any(axis=1)]

# Melihat bentuk data setelah penyaringan
filtered_df.shape

"""Jumlah data setelah penyaringan outlier menggunakan metode IQR menjadi `1768` baris dari `2200` baris awal

### **Univariate Analysis**
"""

df = df.rename(columns = {'N':'Nitrogen', 'P':'Phosphorus', 'K':'Potassium',
                          'temperature':'Temperature', 'humidity':'Humidity',
                          'ph':'pH', 'rainfall':'Rainfall', 'label':'Crop'})
categorical_feature = 'Crop'
numerical_feature = df.select_dtypes(include='number').columns.tolist()

df.hist(bins=20, figsize=(20,10))
plt.show()

"""Dapat dilihat pada grafik bahwa sebaran data masing-masing fitur bervariasi

### **Multivariate Analysis**
"""

sns.pairplot(df, hue = 'Crop', diag_kind = 'kde')

corr_matrix = df[numerical_feature].corr().round(2)
sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm')
plt.title('Matriks Korelasi Fitur Numerik')
plt.show()

"""Pada matrik korelasi diatas, dapat diketahui

*   Fitur Phosporus dan Potassium memiliki korelasi positif yang tinggi.
*   Fitur Rainfall tidak memiliki korelasi terhadap fitur lain.

# **Data Preparation**

merupakan proses untuk mempersiapkan data sebelum dilakukan tahap pembuatan model machine learning

## **Data Cleaning**
"""

label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(df['Crop'])
df['label'] = labels
df.head()

"""data crop diberikan label unik dengan menggunakan fungi `labelEncoder()` untuk memudahkan saat data preparation dan model development.

## **Train Test Split**
"""

x = df[df.select_dtypes(include=np.number).columns.drop('label')]
y = df['label']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)

print(f'Total # of sample in whole dataset: {len(x)}')
print(f'Total # of sample in train dataset: {len(x_train)}')
print(f'Total # of sample in test dataset: {len(x_test)}')

"""## **Normalisasi**"""

scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

"""Rentang nilai pada data numerik bervariasi sehingga diperlukan normalisasi agar rentang nilai data memiliki skala yang sama. Hal ini juga berpengaruh pada pengembangan model yang sensitif terhadap skala.

# **Model Development**

### **Lazy Predict**

LazyPredict adalah pustaka Python yang memudahkan proses pemilihan model machine learning. Ia melakukan ini dengan secara otomatis mengevaluasi dan membandingkan berbagai algoritma pembelajaran mesin pada kumpulan data.

Keuntungan menggunakan LazyPredict:
Cepat dan efisien: LazyPredict dapat dengan cepat mengevaluasi dan membandingkan banyak model, menghemat waktu dan tenaga.
Mempermudah identifikasi model potensial: Alih-alih mencoba berbagai model secara manual, LazyPredict membantu menemukan model yang berpotensi berkinerja baik pada data.
Cocok untuk analisis awal dan pembuatan prototipe: LazyPredict memudahkan untuk memulai dengan proyek machine learning dengan cepat tanpa terjebak dalam detail pemilihan model.
"""

!pip install lazypredict

from lazypredict.Supervised import LazyClassifier
clf = LazyClassifier()
models,predicts = clf.fit(x_train,x_test,y_train,y_test)
print(models.sort_values(by="Accuracy",ascending=False))

temp = models.sort_values(by="Accuracy",ascending=True)
plt.figure(figsize=(10, 8))
plt.barh(temp.index,temp["Accuracy"])
plt.show()

"""### **Pembuatan Model**

Mempersiapkan DataFrame untuk Analisis Model
"""

model = pd.DataFrame(index = ['train_cc', 'test_acc'],
                            columns = ['SVM', 'MLP', 'RF', 'GB'])

"""Membuat Model Support Vector Machine (SVM)"""

svm = SVC()
svm.fit(x_train, y_train)

model.loc['train_acc', 'SVM'] = accuracy_score( y_pred = svm.predict(x_train), y_true = y_train)

"""Membuat Model Multi Layer Perceptron (MLP)"""

mlp = MLPClassifier()
mlp.fit(x_train, y_train)

model.loc['train_acc', 'MLP'] = accuracy_score(y_pred = mlp.predict(x_train), y_true = y_train)

"""Membuat Model Multi Layer Perceptron (MLP)"""

rf = RandomForestClassifier(max_depth=20)
rf.fit(x_train, y_train)

model.loc['train_acc', 'RF'] = accuracy_score(y_pred = rf.predict(x_train), y_true = y_train)

"""Parameter yang digunakan yaitu `max_depth` sebesar 20 berfungsi untuk menentukan kedalaman maksimum tiap pohon keputusan dalam Random Forest.

Membuat Model Gradient Boosting
"""

gb = GradientBoostingClassifier(learning_rate=0.001, n_estimators=200)
gb.fit(x_train, y_train)

model.loc['train_acc', 'GB'] = accuracy_score(y_pred = gb.predict(x_train), y_true = y_train)

"""Parameter yang digunakan


*   `learning_rate` = 0.001. Bobot yang diterapkan pada setiap classfier di masing-masing proses iterasi boosting.
*   `n_estimator`  = 200.  Jumlah pohon keputusan (weak learners) yang akan dibangun dalam model.

# **Evaluasi Model**
"""

# Buat dataframe untuk menyimpan akurasi data train dan test
acc = pd.DataFrame(columns=['train', 'test'], index=['SVM', 'MLP', 'RF', 'GB'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'SVM': svm, 'MLP': mlp, 'RF': rf, 'GB': gb}

# Hitung akurasi untuk setiap algoritma
for name, model in model_dict.items():
    # Prediksi pada data train dan test
    y_train_pred = model.predict(x_train)
    y_test_pred = model.predict(x_test)

    # Simpan akurasi ke dalam dataframe
    acc.loc[name, 'train'] = accuracy_score(y_true=y_train, y_pred=y_train_pred)
    acc.loc[name, 'test'] = accuracy_score(y_true=y_test, y_pred=y_test_pred)

# Tampilkan dataframe acc
acc

fig, ax = plt.subplots()
acc.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = x_test[:1].copy()
pred_dict = {'y_true':y_test[:1].values.tolist()[0]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi)[0].tolist()

pd.DataFrame([pred_dict])